{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace(subscription_id=\"ab0fea7d-9046-495f-840d-19a0430c1d73\",\n",
    "               resource_group=\"aisejam\",\n",
    "               workspace_name=\"amlsejam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model bidaf_onnx\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Download model\n",
    "urllib.request.urlretrieve(\"https://aka.ms/bidaf-9-model\", \"model.onnx\")\n",
    "\n",
    "# Register model\n",
    "model = Model.register(ws, model_name=\"bidaf_onnx\", model_path=\"./model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment(name=\"project_environment\")\n",
    "dummy_inference_config = InferenceConfig(\n",
    "    environment=env,\n",
    "    source_directory=\"./source_dir\",\n",
    "    entry_script=\"./echo_score.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "# deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
    "\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=0.5, memory_gb=1, auth_enabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/hw443_ds36985hq1dr8c1nmm0000gn/T/ipykernel_25933/1673426657.py:1: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration. \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2023-01-09 11:21:59+09:00 Creating Container Registry if not exists..\n",
      "2023-01-09 11:31:59+09:00 Registering the environment.\n",
      "2023-01-09 11:32:00+09:00 Building image..\n",
      "2023-01-09 11:42:14+09:00 Generating deployment configuration.\n",
      "2023-01-09 11:42:14+09:00 Submitting deployment to compute..\n",
      "2023-01-09 11:42:22+09:00 Checking the status of deployment myservice..\n",
      "2023-01-09 11:45:05+09:00 Checking the status of inference endpoint myservice.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "/bin/bash: /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2023-01-09T02:44:50,578307119+00:00 - rsyslog/run \n",
      "2023-01-09T02:44:50,578636219+00:00 - iot-server/run \n",
      "2023-01-09T02:44:50,601801719+00:00 - gunicorn/run \n",
      "2023-01-09T02:44:50,605157319+00:00 | gunicorn/run | \n",
      "bash: /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "2023-01-09T02:44:50,618047719+00:00 | gunicorn/run | ###############################################\n",
      "2023-01-09T02:44:50,636418019+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2023-01-09T02:44:50,638334119+00:00 | gunicorn/run | ###############################################\n",
      "2023-01-09T02:44:50,640924119+00:00 | gunicorn/run | \n",
      "2023-01-09T02:44:50,653191319+00:00 | gunicorn/run | \n",
      "2023-01-09T02:44:50,675157219+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20221101.v11\n",
      "2023-01-09T02:44:50,683941819+00:00 - nginx/run \n",
      "2023-01-09T02:44:50,698315519+00:00 | gunicorn/run | \n",
      "2023-01-09T02:44:50,703285019+00:00 | gunicorn/run | \n",
      "2023-01-09T02:44:50,707797319+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2023-01-09T02:44:50,714122419+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2023-01-09T02:44:50,719305619+00:00 | gunicorn/run | \n",
      "2023-01-09T02:44:50,727524219+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2023-01-09T02:44:52,061625519+00:00 - iot-server/finish 1 0\n",
      "2023-01-09T02:44:52,063195019+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "adal==1.2.7\n",
      "argcomplete==2.0.0\n",
      "attrs==22.2.0\n",
      "azure-common==1.1.28\n",
      "azure-core==1.26.2\n",
      "azure-graphrbac==0.61.1\n",
      "azure-identity==1.7.0\n",
      "azure-mgmt-authorization==3.0.0\n",
      "azure-mgmt-containerregistry==10.0.0\n",
      "azure-mgmt-core==1.3.2\n",
      "azure-mgmt-keyvault==10.1.0\n",
      "azure-mgmt-resource==21.2.1\n",
      "azure-mgmt-storage==20.1.0\n",
      "azureml-core==1.48.0\n",
      "azureml-dataprep==4.8.3\n",
      "azureml-dataprep-native==38.0.0\n",
      "azureml-dataprep-rslex==2.15.1\n",
      "azureml-dataset-runtime==1.48.0\n",
      "azureml-defaults==1.48.0\n",
      "azureml-inference-server-http==0.7.7\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==4.0.1\n",
      "cachetools==5.2.1\n",
      "certifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\n",
      "cffi==1.15.1\n",
      "charset-normalizer==2.1.1\n",
      "click==8.1.3\n",
      "cloudpickle==2.2.0\n",
      "contextlib2==21.6.0\n",
      "cryptography==38.0.4\n",
      "distro==1.8.0\n",
      "docker==6.0.1\n",
      "dotnetcore2==3.1.23\n",
      "Flask==2.2.2\n",
      "Flask-Cors==3.0.10\n",
      "fusepy==3.0.1\n",
      "google-api-core==2.11.0\n",
      "google-auth==2.15.0\n",
      "googleapis-common-protos==1.57.1\n",
      "gunicorn==20.1.0\n",
      "humanfriendly==10.0\n",
      "idna==3.4\n",
      "importlib-metadata==6.0.0\n",
      "importlib-resources==5.10.2\n",
      "inference-schema==1.5.1\n",
      "isodate==0.6.1\n",
      "itsdangerous==2.1.2\n",
      "jeepney==0.8.0\n",
      "Jinja2==3.1.2\n",
      "jmespath==1.0.1\n",
      "jsonpickle==2.2.0\n",
      "jsonschema==4.17.3\n",
      "knack==0.10.1\n",
      "MarkupSafe==2.1.1\n",
      "msal==1.20.0\n",
      "msal-extensions==0.3.1\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4\n",
      "ndg-httpsclient==0.5.1\n",
      "numpy==1.24.1\n",
      "oauthlib==3.2.2\n",
      "opencensus==0.11.0\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.7\n",
      "packaging==21.3\n",
      "paramiko==2.12.0\n",
      "pathspec==0.10.3\n",
      "pkginfo==1.9.6\n",
      "pkgutil_resolve_name==1.3.10\n",
      "portalocker==2.6.0\n",
      "protobuf==4.21.12\n",
      "psutil==5.9.4\n",
      "pyarrow==9.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser==2.21\n",
      "Pygments==2.14.0\n",
      "PyJWT==2.6.0\n",
      "PyNaCl==1.5.0\n",
      "pyOpenSSL==22.1.0\n",
      "pyparsing==3.0.9\n",
      "pyrsistent==0.19.3\n",
      "PySocks==1.7.1\n",
      "python-dateutil==2.8.2\n",
      "pytz==2022.7\n",
      "PyYAML==6.0\n",
      "requests==2.28.1\n",
      "requests-oauthlib==1.3.1\n",
      "rsa==4.9\n",
      "SecretStorage==3.3.3\n",
      "six==1.16.0\n",
      "tabulate==0.9.0\n",
      "typing_extensions==4.4.0\n",
      "urllib3==1.26.13\n",
      "websocket-client==1.4.2\n",
      "Werkzeug==2.2.2\n",
      "wrapt==1.12.1\n",
      "zipp==3.11.0\n",
      "\n",
      "2023-01-09T02:44:55,144393319+00:00 | gunicorn/run | \n",
      "2023-01-09T02:44:55,172213019+00:00 | gunicorn/run | ###############################################\n",
      "2023-01-09T02:44:55,173774719+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2023-01-09T02:44:55,175257319+00:00 | gunicorn/run | ###############################################\n",
      "2023-01-09T02:44:55,176842819+00:00 | gunicorn/run | \n",
      "2023-01-09T02:44:56,850840640+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "\n",
      "Azure ML Inferencing HTTP server v0.7.7\n",
      "\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/source_dir/echo_score.py\n",
      "Model Directory: /var/azureml-app/azureml-models/bidaf_onnx/1\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/0.7.7\n",
      "CORS for the specified origins: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://0.0.0.0:31311 (71)\n",
      "Using worker: sync\n",
      "Booting worker with pid: 128\n",
      "Initializing logger\n",
      "2023-01-09 02:45:00,650 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2023-01-09 02:45:00,651 | root | INFO | Starting up app insight hooks\n",
      "2023-01-09 02:45:00,653 | root | INFO | Found user script at /var/azureml-app/source_dir/echo_score.py\n",
      "2023-01-09 02:45:00,655 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2023-01-09 02:45:00,655 | root | INFO | Invoking user's init function\n",
      "00000000-0000-0000-0000-000000000000,This is init\n",
      "2023-01-09 02:45:00,657 | root | INFO | Users's init has completed successfully\n",
      "2023-01-09 02:45:00,666 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\n",
      "2023-01-09 02:45:00,666 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2023-01-09 02:45:00,667 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "2023-01-09 02:45:05,355 | root | INFO | 200\n",
      "127.0.0.1 - - [09/Jan/2023:02:45:05 +0000] \"GET /swagger.json HTTP/1.0\" 200 2251 \"-\" \"Go-http-client/1.1\"\n",
      "2023-01-09 02:45:10,339 | root | INFO | 200\n",
      "127.0.0.1 - - [09/Jan/2023:02:45:10 +0000] \"GET /swagger.json HTTP/1.0\" 200 2251 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(\n",
    "    ws,\n",
    "    \"myservice\",\n",
    "    [model],\n",
    "    dummy_inference_config,\n",
    "    deployment_config,\n",
    "    overwrite=True,\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec39cc0edeeb3d99a2d0ab8aa3cdebae510cfbc8eab7a85c7e9528156c6445b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
